
# ðŸ“° News Intelligence Pipeline

**An End-to-End Real-Time News Analysis System**

![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![Kafka](https://img.shields.io/badge/Kafka-Streaming-black.svg)
![Spark](https://img.shields.io/badge/Spark-Processing-orange.svg)
![Postgres](https://img.shields.io/badge/Postgres-Storage-blue.svg)
![Django](https://img.shields.io/badge/Django-API-green.svg)

## ðŸš€ Overview
The **News Intelligence Pipeline** is a scalable data engineering project that scrapes news from major global sources, processes them in real-time, enriches them with AI (Sentiment Analysis & Embeddings), and exposes the insights via a RAG-enabled API.

It transforms raw unstructured text into **smart, searchable intelligence**.

## ðŸ—ï¸ Architecture

```mermaid
graph LR
    A[Scrapers] -->|JSON| B(Kafka Topic)
    B -->|Stream| C{Spark Streaming}
    C -->|Clean & Dedup| D[(Postgres DB)]
    C -->|Raw Parquet| E[MinIO Data Lake]
    D -->|New Articles| F[NLP Microservice]
    F -->|Sentiment & Vectors| D
    F -->|Embeddings| G[(ChromaDB)]
    H[User] -->|REST API| I[Django Backend]
    I <-->|SQL Query| D
    I <-->|Semantic Search| G
```

## ðŸ› ï¸ Tech Stack
*   **Ingestion**: Python (Selenium/BeautifulSoup) -> Apache Kafka
*   **Processing**: Apache Spark (Structured Streaming)
*   **Storage**: PostgreSQL (Metadata/Enriched) + MinIO (Data Lake)
*   **AI/NLP**:
    *   Sentiment: HuggingFace Transformers (`distilbert`)
    *   Embeddings: SentenceTransformers (`all-MiniLM-L6-v2`)
    *   RAG: ChromaDB (Vector Store)
*   **API**: Django REST Framework (DRF)

## ðŸ“‚ Project Structure
```bash
news-intelligence-pipeline/
â”œâ”€â”€ api/                  # Django REST API
â”œâ”€â”€ config/               # Configuration (Kafka, Spark)
â”œâ”€â”€ ingestion/            # News Scrapers & Kafka Producers
â”œâ”€â”€ nlp/                  # AI Models (Sentiment, Embeddings)
â”œâ”€â”€ processing/           # Spark Streaming Jobs
â”œâ”€â”€ scripts/              # Utility Scripts (Setup, Verification)
â”œâ”€â”€ storage/              # Database Models & Managers
â”œâ”€â”€ vector_store/         # ChromaDB Client
â””â”€â”€ docker-compose.yml    # Infrastructure (Kafka, Zookeeper, Postgres, MinIO)
```

## âš¡ Quick Start

### 1. Prerequisites
*   Docker & Docker Compose
*   Python 3.9+
*   Java 11 (for Spark local dev)

### 2. Setup Infrastructure
Start the core services (Kafka, Postgres, MinIO):
```bash
docker-compose up -d
```

### 3. Install Dependencies
```bash
python -m venv .venv
# Windows: .venv\Scripts\Activate
# Mac/Linux: source .venv/bin/activate

pip install -r requirements.txt
pip install -r requirements_spark.txt
```

### 4. Initialize Database
Create tables in Postgres:
```bash
python scripts/init_storage.py
```

### 5. Run the Pipeline (Simulation)
**A. Start API Server:**
```bash
python api/manage.py runserver
```

**B. Scrape & Ingest Data:**
```bash
python scripts/load_test.py
# Scrapes BBC/CNN -> Sends to Kafka
```

**C. Process Data (Spark):**
```bash
python processing/spark/streaming/spark_streaming_job.py
# Reads Kafka -> Writes to DB & MinIO
```

**D. Enrich Data (AI):**
```bash
python nlp/enrichment_service.py
# Calculates Sentiment & Embeddings -> Updates DB
```

**E. Index Vectors:**
```bash
python scripts/sync_db_to_vector.py
# Syncs Embeddings to ChromaDB
```

## ðŸ”Œ API Documentation

### Get News Articles
**Endpoint**: `GET /api/news/`
```json
[
  {
    "id": 1,
    "title": "Global Markets Rally...",
    "source": "Reuters",
    "sentiment_label": "POSITIVE",
    "sentiment_score": 95
  }
]
```

### RAG Chat (Semantic Search)
**Endpoint**: `POST /api/chat/`
**Body**: `{"query": "What is happening in Venezuela?"}`
**Response**:
```json
{
  "answer": "Here are the most relevant news articles:",
  "results": [
    {
      "text": "Venezuela says over 100 political prisoners released...",
      "metadata": { "source": "AlJazeera", "sentiment": "POSITIVE" }
    }
  ]
}
```

## ðŸ”® Future Roadmap
- [ ] React/Streamlit Frontend Dashboard
- [ ] Kubernetes Deployment (Helm Charts)
- [ ] LLM Integration (DeepSeek/OpenAI) for full answer generation
